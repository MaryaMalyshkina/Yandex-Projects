# Описание проекта
Компания собрала исторические данные о заказах такси в аэропортах. 

Чтобы привлекать больше водителей в период пиковой нагрузки, 
нужно спрогнозировать количество заказов такси на следующий час. 

Необходимо построить модель для такого предсказания.

# Навыки и инструменты
- pandas
- matplotlib
- seaborn
- numpy
- statsmodels
- skforecast
- scipy.stats
- statsmodels.graphics.tsaplots.plot_acf
- sklearn.model_selection.TimeSeriesSplit
- sklearn.linear_model.LinearRegression
- sklearn.metrics.root_mean_squared_error
- sklearn.tree.DecisionTreeClassifier
- sklearn.tree.DecisionTreeRegressor
- sklearn.model_selection.GridSearchCV
- prophet.Prophet
- skforecast.sarimax.Sarimax

# Общий вывод
1. Проанализирован временной ряд числа заказов:
2. 
выделен тренд, сезонная компонента и остатки.
Построен график автокорреляционной функции.
С помощью теста Дики-Фуллера оценена стационарность временного ряда.

3. В проекте рассмотрены 4  разные модели:
линейная регрессия, Prophet, SARIMAX и DecisionTreeRegressor.

Для обучения вся выборка данных была поделена на тренировочную, валидационную и тестовую в соотношении 8:1:1.

Качество каждой модели оценивалось на валидационной выборке по метрике RSME,
наилучшая модель  выбиралась по наименьшему значению этой метрики.

3. Для линейной регрессии и DecisionTreeRegressor дополнительно вводились новые признаки:

  - час, день , месяц и день недели,
  - столбцы с предыдущими значениями с лагом от 1 до заданного max_lag,
  - скользящее среднее с заданной шириной окна rolling_mean_size.

В цикле перебирались разные значения лага и ширины окна, создавался набор признаков, модель обучалась на этих признаках,
и рассчитывалась RSME на валидационной выборке.

Для DecisionTreeRegressor гиперпараметры для дерева подбирались с помощью GridSearchCV 
и кросс-валидацией для временных рядов с помощью TimeSeriesSplit. 

4. Формально лучшей моделью по метрике RSME на валидационной выборке стала DecisionTreeRegressor, 
но на тестовой она выдала  значение выше требуемого, поэтому лучшей в итоге 
признана модель линейной регрессии (с добавлением дополнительных признаков в модель), 
для которой RSME на тестовой выборке удовлетворяет условию.

В целом, все рассмотренные модели угадали периодичность, но сильно занизили амплитуду пиков.
Линейная регресия не только аккуратно подобрала шаг периодичности, но и лучше справилась с амплитудой пиков, 
поэтому считаем, что она показала наилучший результат в задаче прогноза числа заказов.

5. Для линейной регрессии оценена важность признаков: самый большой вес в модель по сравнению со всеми остальными признаками внес месяц. 

